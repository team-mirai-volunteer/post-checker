{"data":"app:\n  description: ''\n  icon: \ud83e\udd16\n  icon_background: '#FFEAD5'\n  mode: advanced-chat\n  name: PostChecker\n  use_icon_as_answer_icon: false\ndependencies:\n- current_identifier: null\n  type: marketplace\n  value:\n    marketplace_plugin_unique_identifier: langgenius\/openai:0.2.8@aae2be0913b8c6f0b80cff58e08d7a8b4c214569b41778413fcaea204561ff16\n    version: null\nkind: app\nversion: 0.5.0\nworkflow:\n  conversation_variables: []\n  environment_variables: []\n  features:\n    file_upload:\n      allowed_file_extensions:\n      - .JPG\n      - .JPEG\n      - .PNG\n      - .GIF\n      - .WEBP\n      - .SVG\n      allowed_file_types:\n      - image\n      allowed_file_upload_methods:\n      - local_file\n      - remote_url\n      enabled: false\n      fileUploadConfig:\n        attachment_image_file_size_limit: 2\n        audio_file_size_limit: 50\n        batch_count_limit: 5\n        file_size_limit: 15\n        file_upload_limit: 20\n        image_file_batch_limit: 10\n        image_file_size_limit: 10\n        single_chunk_attachment_limit: 10\n        video_file_size_limit: 100\n        workflow_file_upload_limit: 10\n      image:\n        enabled: false\n        number_limits: 3\n        transfer_methods:\n        - local_file\n        - remote_url\n      number_limits: 3\n    opening_statement: ''\n    retriever_resource:\n      enabled: false\n    sensitive_word_avoidance:\n      enabled: false\n    speech_to_text:\n      enabled: false\n    suggested_questions: []\n    suggested_questions_after_answer:\n      enabled: false\n    text_to_speech:\n      enabled: false\n      language: ''\n      voice: ''\n  graph:\n    edges:\n    - data:\n        sourceType: start\n        targetType: knowledge-retrieval\n      id: 1711528914102-1711528915811\n      source: '1711528914102'\n      sourceHandle: source\n      target: '1711528915811'\n      targetHandle: target\n      type: custom\n    - data:\n        sourceType: knowledge-retrieval\n        targetType: llm\n      id: 1711528915811-1711528917469\n      source: '1711528915811'\n      sourceHandle: source\n      target: '1711528917469'\n      targetHandle: target\n      type: custom\n    - data:\n        sourceType: llm\n        targetType: answer\n      id: 1711528917469-1711528919501\n      source: '1711528917469'\n      sourceHandle: source\n      target: '1711528919501'\n      targetHandle: target\n      type: custom\n    nodes:\n    - data:\n        desc: ''\n        selected: false\n        title: Start\n        type: start\n        variables: []\n      height: 73\n      id: '1711528914102'\n      position:\n        x: 79.5\n        y: 2634.5\n      positionAbsolute:\n        x: 79.5\n        y: 2634.5\n      selected: false\n      sourcePosition: right\n      targetPosition: left\n      type: custom\n      width: 242\n    - data:\n        dataset_ids:\n        - P9BenPtuC1vfag+nJM6R+w1zFZ+mLapQ8zeCfNPUf6fCQfiGxq\/XjOBdg7ZR9LdM\n        desc: Allows you to query text content related to user questions from the\n          Knowledge\n        query_variable_selector:\n        - '1711528914102'\n        - sys.query\n        retrieval_mode: single\n        selected: false\n        single_retrieval_config:\n          model:\n            completion_params:\n              frequency_penalty: 0\n              max_tokens: 512\n              presence_penalty: 0\n              temperature: 0\n              top_p: 1\n            mode: chat\n            name: gpt-3.5-turbo\n            provider: openai\n        title: Knowledge Retrieval\n        type: knowledge-retrieval\n      dragging: false\n      height: 112\n      id: '1711528915811'\n      position:\n        x: 362.5\n        y: 2634.5\n      positionAbsolute:\n        x: 362.5\n        y: 2634.5\n      selected: false\n      sourcePosition: right\n      targetPosition: left\n      type: custom\n      width: 242\n    - data:\n        context:\n          enabled: false\n          variable_selector: []\n        desc: Invoking large language models to answer questions or process natural\n          language\n        memory:\n          role_prefix:\n            assistant: ''\n            user: ''\n          window:\n            enabled: false\n            size: 50\n        model:\n          completion_params:\n            frequency_penalty: 0\n            max_tokens: 512\n            presence_penalty: 0\n            temperature: 0.7\n            top_p: 1\n          mode: chat\n          name: gpt-3.5-turbo\n          provider: langgenius\/openai\/openai\n        prompt_template:\n        - id: e4455dd3-494b-4b72-84a4-c714d87c17a6\n          role: system\n          text: \"You are a helpful assistant. \\nUse the following context as your\\\n            \\ learned knowledge, inside <context><\/context> XML tags.\\n<context>\\n\\\n            {{#context#}}\\n<\/context>\\nWhen answer to user:\\n- If you don't know,\\\n            \\ just say that you don't know.\\n- If you don't know when you are not\\\n            \\ sure, ask for clarification.\\nAvoid mentioning that you obtained the\\\n            \\ information from the context.\\nAnd answer according to the language\\\n            \\ of the user's question.\"\n        selected: true\n        title: LLM\n        type: llm\n        variables: []\n        vision:\n          enabled: false\n      height: 148\n      id: '1711528917469'\n      position:\n        x: 645.5\n        y: 2634.5\n      positionAbsolute:\n        x: 645.5\n        y: 2634.5\n      selected: true\n      sourcePosition: right\n      targetPosition: left\n      type: custom\n      width: 242\n    - data:\n        answer: '{{#1711528917469.text#}}'\n        desc: ''\n        selected: false\n        title: Answer\n        type: answer\n        variables: []\n      height: 103\n      id: '1711528919501'\n      position:\n        x: 928.5\n        y: 2634.5\n      positionAbsolute:\n        x: 928.5\n        y: 2634.5\n      selected: false\n      sourcePosition: right\n      targetPosition: left\n      type: custom\n      width: 242\n    viewport:\n      x: 299.91563435138517\n      y: -2095.69386924012\n      zoom: 0.9753554615276419\n  rag_pipeline_variables: []\n"}
